[#scenario-01,cols="3"]
.Scenario #1: AAP Gateway Troubleshooting
|===
| **Mode** | **Components** | **Namespace**

| Easy
| AAP Gateway UI
| `aap-rh1`
|===

### üìù Objectives

* Find out why the **AAP Gateway** pods are failing to start or run correctly.
* Log in to the **AAP UI** to verify that the application is fully operational after remediation.

---

### üí° Hint

* Use standard Kubernetes tooling (e.g., `oc` or `kubectl`) to inspect the state of the pods in the assigned namespace. Are there any pods in a non-`Running` or `Completed` state?

---

### üõ†Ô∏è Prerequisites: Setup and Break

This section performs the initial setup and then injects a known failure into the environment for this scenario.

#### 1. Initial Deployment

Run the main playbook to deploy the required environment components (if not already done).

[.instruction]
====
Execute the following command, then select **Scenario 4** when prompted.
====

[source,bash]
----
ansible-playbook site.yml -t deploy
----

#### 2. Introduce Failure (Break)

Execute the playbook to introduce the specific error for Scenario #1.

[.instruction]
====
Execute the following command, then select **Scenario 4** when prompted.
====

[source,bash]
----
ansible-playbook site.yml -t break
----

[NOTE]
====
This `break` command simulates an issue that typically causes **Gateway pods** to fail health checks or crash. Your task is to use your existing knowledge to diagnose and fix the root cause.
====

---

### ‚úÖ Steps to Resolution

#### Step 1: Inspect Pod Status

[.instruction]
====
Inspect the status of the pods in your assigned namespace (`aap-rh1`). Look specifically for pods related to the AAP Gateway.
====

[source,bash]
----
# Example inspection command
oc get pods -n aap-rh1
----

[.output]
====
Identify any pods that show a status like `CrashLoopBackOff`, `Error`, or a readiness/liveness probe failure. Note the full name of the failing Gateway pod.
====

[TIP]
====
If a pod is in a `CrashLoopBackOff` state, you need to check the logs to see what error is causing it to restart repeatedly.
====

#### Step 2: Examine Pod Logs

[.instruction]
====
View the logs for the failing Gateway pod to determine the specific cause of the crash or failure.
====

[source,bash]
----
oc logs -n aap-rh1 <failing-gateway-pod-name>
----

[.output]
====
The logs should indicate a specific error related to configuration or resource access that prevents the service from starting correctly. This is your primary clue.
====

#### Step 3: Implement the Fix

(Your solution steps go here. These are typically environment-specific, e.g., editing a ConfigMap, fixing an image name in a Deployment, or adjusting a security context.)

[.instruction]
====
Apply the necessary fix based on the logs you reviewed in Step 2.
====

[source,bash]
----
# Example: Apply a fixed configuration file
oc apply -f fixed-config.yaml -n aap-rh1
----

[NOTE]
====
Often, a fix will require the failing pod to be automatically restarted by the deployment or to be manually deleted (`oc delete pod <pod-name>`) to pick up the new, corrected configuration.
====

#### Step 4: Verify Resolution

[.instruction]
====
Once the fix is applied, verify that the Gateway pods transition to a `Running` and ready state.
====

[source,bash]
----
oc get pods -n aap-rh1
----

[.output]
====
All Gateway-related pods should now show:

* **STATUS:** `Running`
* **READY:** `X/X` (e.g., `1/1`)
====

#### Step 5: Final UI Check

[.instruction]
====
Log in to the **AAP UI** via the provided route/URL to ensure the application is fully accessible and functional.
====

[.output]
====
A successful login and ability to navigate the main dashboard confirms the scenario is complete.
====